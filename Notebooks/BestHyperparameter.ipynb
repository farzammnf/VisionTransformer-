{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-06-14T06:45:46.085735Z","iopub.status.idle":"2024-06-14T06:45:46.086173Z","shell.execute_reply":"2024-06-14T06:45:46.085971Z","shell.execute_reply.started":"2024-06-14T06:45:46.085954Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:03:59.395137Z","iopub.status.busy":"2024-06-14T07:03:59.394782Z","iopub.status.idle":"2024-06-14T07:03:59.401757Z","shell.execute_reply":"2024-06-14T07:03:59.400522Z","shell.execute_reply.started":"2024-06-14T07:03:59.395109Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","# # Hyperparameters\n","# num_classes = 10\n","# patch_size = 16\n","# embedding_dim = 768\n","# num_heads = 12\n","# num_layers = 12\n","# learning_rate = 1e-4\n","# num_epochs = 10\n","# batch_size = 32\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:03:59.534538Z","iopub.status.busy":"2024-06-14T07:03:59.533982Z","iopub.status.idle":"2024-06-14T07:03:59.538578Z","shell.execute_reply":"2024-06-14T07:03:59.537713Z","shell.execute_reply.started":"2024-06-14T07:03:59.534514Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:04:31.716933Z","iopub.status.busy":"2024-06-14T07:04:31.716547Z","iopub.status.idle":"2024-06-14T07:04:31.721626Z","shell.execute_reply":"2024-06-14T07:04:31.720507Z","shell.execute_reply.started":"2024-06-14T07:04:31.716904Z"},"trusted":true},"outputs":[],"source":["# Clear CUDA cache\n","torch.cuda.empty_cache()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:04:32.069631Z","iopub.status.busy":"2024-06-14T07:04:32.069056Z","iopub.status.idle":"2024-06-14T07:04:32.078655Z","shell.execute_reply":"2024-06-14T07:04:32.077651Z","shell.execute_reply.started":"2024-06-14T07:04:32.069600Z"},"trusted":true},"outputs":[],"source":["class VisionTransformer(nn.Module):\n","    def __init__(self, num_classes, patch_size, embedding_dim, num_heads, num_layers):\n","        super(VisionTransformer, self).__init__()\n","        self.patch_embedding = nn.Conv2d(3, embedding_dim, kernel_size=patch_size, stride=patch_size)\n","        self.positional_encoding = nn.Parameter(torch.randn(1, 14 * 14 + 1, embedding_dim))\n","        self.transformer_layers = nn.ModuleList([\n","            nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads) for _ in range(num_layers)\n","        ])\n","        self.fc = nn.Linear(embedding_dim, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = self.patch_embedding(x)\n","        x = x.flatten(2).transpose(1, 2)\n","        x = torch.cat((x, self.positional_encoding.repeat(batch_size, 1, 1)), dim=1)\n","        for layer in self.transformer_layers:\n","            x = layer(x)\n","        x = x.mean(dim=1)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:04:32.402037Z","iopub.status.busy":"2024-06-14T07:04:32.401130Z","iopub.status.idle":"2024-06-14T07:04:33.346958Z","shell.execute_reply":"2024-06-14T07:04:33.346161Z","shell.execute_reply.started":"2024-06-14T07:04:32.401975Z"},"trusted":true},"outputs":[],"source":["# Initialize the model\n","model = VisionTransformer(num_classes, patch_size, embedding_dim, num_heads, num_layers).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:04:37.963441Z","iopub.status.busy":"2024-06-14T07:04:37.962760Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=4, learning_rate=0.0001, batch_size=16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3125/3125 [05:13<00:00,  9.98it/s, Loss=1.58, Accuracy=31.3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 39.06%\n","Saving model with validation accuracy: 39.06%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3125/3125 [05:16<00:00,  9.86it/s, Loss=1.72, Accuracy=43.6] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 46.37%\n","Saving model with validation accuracy: 46.37%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3125/3125 [05:15<00:00,  9.91it/s, Loss=1.55, Accuracy=50.4] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 51.36%\n","Saving model with validation accuracy: 51.36%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3125/3125 [05:14<00:00,  9.93it/s, Loss=1.33, Accuracy=54.5] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 55.74%\n","Saving model with validation accuracy: 55.74%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 3125/3125 [05:13<00:00,  9.98it/s, Loss=1.2, Accuracy=57.2]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 56.83%\n","Saving model with validation accuracy: 56.83%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=4, learning_rate=0.0001, batch_size=32\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 1563/1563 [05:01<00:00,  5.19it/s, Loss=1.85, Accuracy=30.6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 37.70%\n","Saving model with validation accuracy: 37.70%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 1563/1563 [04:59<00:00,  5.21it/s, Loss=1.7, Accuracy=42.4] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 47.31%\n","Saving model with validation accuracy: 47.31%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 1563/1563 [04:58<00:00,  5.23it/s, Loss=1.36, Accuracy=49.3] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 51.49%\n","Saving model with validation accuracy: 51.49%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 1563/1563 [04:57<00:00,  5.25it/s, Loss=1.2, Accuracy=53.7]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 53.94%\n","Saving model with validation accuracy: 53.94%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 1563/1563 [04:57<00:00,  5.26it/s, Loss=1.62, Accuracy=56.5] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 58.24%\n","Saving model with validation accuracy: 58.24%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=4, learning_rate=5e-05, batch_size=16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3125/3125 [05:16<00:00,  9.86it/s, Loss=1.79, Accuracy=29.3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 34.76%\n","Saving model with validation accuracy: 34.76%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3125/3125 [05:16<00:00,  9.87it/s, Loss=1.58, Accuracy=39.4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 42.70%\n","Saving model with validation accuracy: 42.70%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3125/3125 [05:16<00:00,  9.87it/s, Loss=1.95, Accuracy=46]   \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 48.83%\n","Saving model with validation accuracy: 48.83%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3125/3125 [05:15<00:00,  9.89it/s, Loss=1.72, Accuracy=50.3] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 50.17%\n","Saving model with validation accuracy: 50.17%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 3125/3125 [05:15<00:00,  9.91it/s, Loss=1.42, Accuracy=53.7] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 55.21%\n","Saving model with validation accuracy: 55.21%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=4, learning_rate=5e-05, batch_size=32\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 1563/1563 [05:01<00:00,  5.19it/s, Loss=1.78, Accuracy=29]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 35.30%\n","Saving model with validation accuracy: 35.30%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 1563/1563 [05:00<00:00,  5.20it/s, Loss=1.89, Accuracy=37.8]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 42.42%\n","Saving model with validation accuracy: 42.42%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 1563/1563 [05:00<00:00,  5.21it/s, Loss=1.75, Accuracy=43.9]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 45.20%\n","Saving model with validation accuracy: 45.20%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 1563/1563 [04:59<00:00,  5.22it/s, Loss=1.72, Accuracy=48.1]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 49.12%\n","Saving model with validation accuracy: 49.12%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 1563/1563 [04:59<00:00,  5.21it/s, Loss=1.47, Accuracy=51.1] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 53.18%\n","Saving model with validation accuracy: 53.18%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=6, learning_rate=0.0001, batch_size=16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3125/3125 [07:39<00:00,  6.80it/s, Loss=1.58, Accuracy=31.8]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 40.34%\n","Saving model with validation accuracy: 40.34%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3125/3125 [07:38<00:00,  6.81it/s, Loss=1.69, Accuracy=44.8] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 46.74%\n","Saving model with validation accuracy: 46.74%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3125/3125 [07:36<00:00,  6.85it/s, Loss=1.19, Accuracy=51.2] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 54.17%\n","Saving model with validation accuracy: 54.17%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3125/3125 [07:35<00:00,  6.86it/s, Loss=1.47, Accuracy=55.8] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 57.09%\n","Saving model with validation accuracy: 57.09%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 3125/3125 [07:34<00:00,  6.88it/s, Loss=0.975, Accuracy=58.8]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 58.91%\n","Saving model with validation accuracy: 58.91%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=6, learning_rate=0.0001, batch_size=32\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 1563/1563 [07:19<00:00,  3.56it/s, Loss=1.99, Accuracy=31.5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 38.95%\n","Saving model with validation accuracy: 38.95%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 1563/1563 [07:17<00:00,  3.57it/s, Loss=1.04, Accuracy=43.8]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 45.62%\n","Saving model with validation accuracy: 45.62%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 1563/1563 [07:16<00:00,  3.58it/s, Loss=0.746, Accuracy=50.5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 53.58%\n","Saving model with validation accuracy: 53.58%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 1563/1563 [07:16<00:00,  3.58it/s, Loss=1.27, Accuracy=55]   \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 56.24%\n","Saving model with validation accuracy: 56.24%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 1563/1563 [07:15<00:00,  3.59it/s, Loss=1.03, Accuracy=58.3] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 60.51%\n","Saving model with validation accuracy: 60.51%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=6, learning_rate=5e-05, batch_size=16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3125/3125 [07:40<00:00,  6.78it/s, Loss=1.63, Accuracy=30.3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 38.15%\n","Saving model with validation accuracy: 38.15%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3125/3125 [07:40<00:00,  6.79it/s, Loss=1.63, Accuracy=41.4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 45.31%\n","Saving model with validation accuracy: 45.31%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3125/3125 [07:39<00:00,  6.80it/s, Loss=1.8, Accuracy=48.2]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 50.94%\n","Saving model with validation accuracy: 50.94%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3125/3125 [07:39<00:00,  6.80it/s, Loss=1.25, Accuracy=52]   \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 54.43%\n","Saving model with validation accuracy: 54.43%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 3125/3125 [07:38<00:00,  6.82it/s, Loss=1.53, Accuracy=55.2] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 55.46%\n","Saving model with validation accuracy: 55.46%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=4, num_layers=6, learning_rate=5e-05, batch_size=32\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 1563/1563 [07:18<00:00,  3.57it/s, Loss=1.5, Accuracy=30.1] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 34.47%\n","Saving model with validation accuracy: 34.47%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 1563/1563 [07:18<00:00,  3.56it/s, Loss=1.72, Accuracy=40.4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 42.93%\n","Saving model with validation accuracy: 42.93%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 1563/1563 [07:18<00:00,  3.57it/s, Loss=1.48, Accuracy=46.6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 49.26%\n","Saving model with validation accuracy: 49.26%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 1563/1563 [07:18<00:00,  3.56it/s, Loss=1.53, Accuracy=50.6] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 53.18%\n","Saving model with validation accuracy: 53.18%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 1563/1563 [07:18<00:00,  3.57it/s, Loss=1.19, Accuracy=54]   \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 54.97%\n","Saving model with validation accuracy: 54.97%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=8, num_layers=4, learning_rate=0.0001, batch_size=16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3125/3125 [05:30<00:00,  9.44it/s, Loss=1.66, Accuracy=31.6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 38.37%\n","Saving model with validation accuracy: 38.37%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3125/3125 [05:29<00:00,  9.49it/s, Loss=1.19, Accuracy=43.8] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 49.49%\n","Saving model with validation accuracy: 49.49%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3125/3125 [05:27<00:00,  9.54it/s, Loss=1.66, Accuracy=50.8] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 54.21%\n","Saving model with validation accuracy: 54.21%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3125/3125 [05:27<00:00,  9.56it/s, Loss=1.28, Accuracy=54.9] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 54.36%\n","Saving model with validation accuracy: 54.36%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 3125/3125 [05:27<00:00,  9.55it/s, Loss=1.02, Accuracy=57.8] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 58.67%\n","Saving model with validation accuracy: 58.67%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=8, num_layers=4, learning_rate=0.0001, batch_size=32\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 1563/1563 [05:11<00:00,  5.02it/s, Loss=1.62, Accuracy=31]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 39.31%\n","Saving model with validation accuracy: 39.31%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 1563/1563 [05:09<00:00,  5.05it/s, Loss=2.26, Accuracy=42.5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 47.72%\n","Saving model with validation accuracy: 47.72%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 1563/1563 [05:09<00:00,  5.06it/s, Loss=1.21, Accuracy=49.4] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 52.34%\n","Saving model with validation accuracy: 52.34%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 1563/1563 [05:08<00:00,  5.07it/s, Loss=1.16, Accuracy=54.1] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 53.88%\n","Saving model with validation accuracy: 53.88%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 1563/1563 [05:07<00:00,  5.08it/s, Loss=1.75, Accuracy=57.1] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Accuracy: 57.22%\n","Saving model with validation accuracy: 57.22%\n","Running with hyperparameters: patch_size=8, embedding_dim=256, num_heads=8, num_layers=4, learning_rate=5e-05, batch_size=16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 3125/3125 [05:30<00:00,  9.45it/s, Loss=1.94, Accuracy=29.6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Accuracy: 37.16%\n","Saving model with validation accuracy: 37.16%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 3125/3125 [05:30<00:00,  9.46it/s, Loss=1.23, Accuracy=40.2] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Accuracy: 44.97%\n","Saving model with validation accuracy: 44.97%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 3125/3125 [05:29<00:00,  9.47it/s, Loss=1.53, Accuracy=46.8] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Accuracy: 47.76%\n","Saving model with validation accuracy: 47.76%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 3125/3125 [05:29<00:00,  9.49it/s, Loss=1.37, Accuracy=50.9] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Accuracy: 51.91%\n","Saving model with validation accuracy: 51.91%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5:  77%|███████▋  | 2421/3125 [04:14<01:14,  9.50it/s, Loss=1.34, Accuracy=53.7] "]}],"source":["import itertools\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define the hyperparameter space\n","patch_sizes = [8, 16]\n","embedding_dims = [256, 512]\n","num_heads = [4, 8]\n","num_layers = [4, 6]\n","learning_rates = [1e-4, 5e-5]\n","batch_sizes = [16, 32]\n","\n","# CIFAR-10 dataset\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n","\n","# Function to train and evaluate a model\n","def train_and_evaluate_model(patch_size, embedding_dim, num_heads, num_layers, learning_rate, batch_size):\n","    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","    \n","    # Define the Vision Transformer model\n","    class VisionTransformer(nn.Module):\n","        def __init__(self, num_classes, patch_size, embedding_dim, num_heads, num_layers):\n","            super(VisionTransformer, self).__init__()\n","            self.patch_embedding = nn.Conv2d(3, embedding_dim, kernel_size=patch_size, stride=patch_size)\n","            self.positional_encoding = nn.Parameter(torch.randn(1, 14 * 14 + 1, embedding_dim))\n","            self.transformer_layers = nn.ModuleList([\n","                nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads) for _ in range(num_layers)\n","            ])\n","            self.fc = nn.Linear(embedding_dim, num_classes)\n","\n","        def forward(self, x):\n","            batch_size = x.size(0)\n","            x = self.patch_embedding(x)\n","            x = x.flatten(2).transpose(1, 2)\n","            x = torch.cat((x, self.positional_encoding.repeat(batch_size, 1, 1)), dim=1)\n","            for layer in self.transformer_layers:\n","                x = layer(x)\n","            x = x.mean(dim=1)\n","            x = self.fc(x)\n","            return x\n","\n","    # Initialize the model\n","    model = VisionTransformer(num_classes=10, patch_size=patch_size, embedding_dim=embedding_dim, \n","                              num_heads=num_heads, num_layers=num_layers).to(device)\n","\n","    # Loss and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training loop\n","    num_epochs = 5  # Using a smaller number of epochs for hyperparameter search\n","    best_accuracy = 0.0\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0.0\n","        correct = 0\n","        total_samples = 0\n","        \n","        # Use tqdm for progress bar\n","        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}')\n","        \n","        for i, (images, labels) in progress_bar:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            _, predicted = torch.max(outputs, 1)\n","            correct += (predicted == labels).sum().item()\n","            total_samples += labels.size(0)\n","            \n","            total_loss += loss.item()\n","\n","            progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': (correct / total_samples) * 100})\n","\n","        model.eval()\n","        correct = 0\n","        total_samples = 0\n","        with torch.no_grad():\n","            for images, labels in test_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = model(images)\n","                _, predicted = torch.max(outputs, 1)\n","                correct += (predicted == labels).sum().item()\n","                total_samples += labels.size(0)\n","\n","        # Calculate accuracy\n","        accuracy = correct / total_samples * 100\n","\n","        # Print validation accuracy for each epoch\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n","\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            # Save model to /kaggle/working/\n","            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n","            print(f'Saving model with validation accuracy: {best_accuracy:.2f}%')\n","\n","    return best_accuracy\n","best_hyperparameters = None\n","best_validation_accuracy = 0.0\n","\n","for patch_size, embedding_dim, num_heads, num_layers, learning_rate, batch_size in itertools.product(\n","        patch_sizes, embedding_dims, num_heads, num_layers, learning_rates, batch_sizes):\n","    \n","    print(f'Running with hyperparameters: patch_size={patch_size}, embedding_dim={embedding_dim}, '\n","          f'num_heads={num_heads}, num_layers={num_layers}, learning_rate={learning_rate}, batch_size={batch_size}')\n","    \n","    validation_accuracy = train_and_evaluate_model(patch_size, embedding_dim, num_heads, num_layers, learning_rate, batch_size)\n","    \n","    if validation_accuracy > best_validation_accuracy:\n","        best_validation_accuracy = validation_accuracy\n","        best_hyperparameters = {\n","            'patch_size': patch_size,\n","            'embedding_dim': embedding_dim,\n","            'num_heads': num_heads,\n","            'num_layers': num_layers,\n","            'learning_rate': learning_rate,\n","            'batch_size': batch_size\n","        }\n","\n","print(f'Best hyperparameters found: {best_hyperparameters}')\n","print(f'Best validation accuracy found: {best_validation_accuracy:.2f}%')\n"]},{"cell_type":"markdown","metadata":{},"source":["# As it can been seen, the best hyperparamether is \n","> **Validation Accuracy: 60.51%**\n","> \n","> **patch_size=8, embedding_dim=256, num_heads=4, num_layers=6, learning_rate=5e-05, batch_size=16**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
